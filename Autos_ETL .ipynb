{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7867b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b98923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60dc581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read.csv(\"autos.csv\", header=True, inferSchema=True) #Reading Data From CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4881664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- dateCrawled: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- seller: string (nullable = true)\n",
      " |-- offerType: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- abtest: string (nullable = true)\n",
      " |-- vehicleType: string (nullable = true)\n",
      " |-- yearOfRegistration: string (nullable = true)\n",
      " |-- gearbox: string (nullable = true)\n",
      " |-- powerPS: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- kilometer: integer (nullable = true)\n",
      " |-- monthOfRegistration: string (nullable = true)\n",
      " |-- fuelType: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- notRepairedDamage: string (nullable = true)\n",
      " |-- dateCreated: string (nullable = true)\n",
      " |-- nrOfPictures: integer (nullable = true)\n",
      " |-- postalCode: string (nullable = true)\n",
      " |-- lastSeen: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema() #printing Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4f7e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371824"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.count() #getting total Row Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "761c000d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371824"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv_duplicates=df_csv.dropDuplicates() #Droping the Duplicates\n",
    "df_csv_duplicates.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7e2fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'dateCrawled',\n",
       " 'name',\n",
       " 'seller',\n",
       " 'offerType',\n",
       " 'price',\n",
       " 'abtest',\n",
       " 'vehicleType',\n",
       " 'yearOfRegistration',\n",
       " 'gearbox',\n",
       " 'powerPS',\n",
       " 'model',\n",
       " 'kilometer',\n",
       " 'monthOfRegistration',\n",
       " 'fuelType',\n",
       " 'brand',\n",
       " 'notRepairedDamage',\n",
       " 'dateCreated',\n",
       " 'nrOfPictures',\n",
       " 'postalCode',\n",
       " 'lastSeen']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.columns #Getting the Column name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27c9ed3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             price|\n",
      "+-------+------------------+\n",
      "|  count|            371823|\n",
      "|   mean|17295.124087885943|\n",
      "| stddev|  3587958.57312194|\n",
      "|    min|                 0|\n",
      "|    max|              test|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.select('price').describe().show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6256cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------------+------+---------+-----+-------+-----------+------------------+-------+-------+--------+---------+-------------------+--------+----------+-----------------+-------------------+------------+----------+-------------------+\n",
      "|index|        dateCrawled|                name|seller|offerType|price| abtest|vehicleType|yearOfRegistration|gearbox|powerPS|   model|kilometer|monthOfRegistration|fuelType|     brand|notRepairedDamage|        dateCreated|nrOfPictures|postalCode|           lastSeen|\n",
      "+-----+-------------------+--------------------+------+---------+-----+-------+-----------+------------------+-------+-------+--------+---------+-------------------+--------+----------+-----------------+-------------------+------------+----------+-------------------+\n",
      "|    0|2016-03-24 11:52:17|          Golf_3_1.6|privat|  Angebot|  480|   test|       null|              1993|manuell|      0|    golf|   150000|                  0|  benzin|volkswagen|             null|2016-03-24 00:00:00|           0|     70435|2016-04-07 03:16:57|\n",
      "|   16|2016-04-01 12:46:46|         Polo_6n_1_4|privat|  Angebot|  300|   test|       null|              2016|   null|     60|    polo|   150000|                  0|  benzin|volkswagen|             null|2016-04-01 00:00:00|           0|     38871|2016-04-01 12:46:46|\n",
      "|   22|2016-03-23 14:52:51|Opel_Meriva_1.Han...|privat|  Angebot| 2900|   test|       null|              2018|manuell|     90|  meriva|   150000|                  5|  benzin|      opel|             nein|2016-03-23 00:00:00|           0|     49716|2016-03-31 01:16:33|\n",
      "|   26|2016-03-10 19:38:18|Citroen_C4_Grand_...|privat|  Angebot| 5555|control|       null|              2017|manuell|    125|      c4|   125000|                  4|    null|   citroen|             nein|2016-03-10 00:00:00|           0|     31139|2016-03-16 09:16:46|\n",
      "|   31|2016-03-29 16:57:02|Renault_clio_1.2_...|privat|  Angebot|  899|control|       null|              2016|manuell|     60|    clio|   150000|                  6|  benzin|   renault|             null|2016-03-29 00:00:00|           0|     37075|2016-03-29 17:43:07|\n",
      "|   35|2016-03-08 07:54:46|           VW_Golf_3|privat|  Angebot|  350|   test|       null|              2016|manuell|     75|    golf|   150000|                  4|  benzin|volkswagen|             nein|2016-03-08 00:00:00|           0|     19386|2016-03-08 09:44:50|\n",
      "|   37|2016-03-28 17:50:15|Renault_Kangoo_1....|privat|  Angebot| 1500|   test|       null|              2016|   null|      0|  kangoo|   150000|                  1|  diesel|   renault|             nein|2016-03-28 00:00:00|           0|     46483|2016-03-30 09:18:02|\n",
      "|   40|2016-03-26 22:06:17|Suche_Opel_corsa_...|privat|  Angebot|    0|   test|       null|              1990|   null|      0|   corsa|   150000|                  1|  benzin|      opel|             null|2016-03-26 00:00:00|           0|     56412|2016-03-27 17:43:34|\n",
      "|   48|2016-03-25 14:40:12|VW_Golf_6___Klima...|privat|  Angebot| 7750|control|       null|              2017|manuell|     80|    golf|   100000|                  1|  benzin|volkswagen|             null|2016-03-25 00:00:00|           0|     48499|2016-03-31 21:47:44|\n",
      "|   51|2016-03-07 18:57:08|Fiat_punto_5_tuer...|privat|  Angebot| 2000|control|       null|              2017|manuell|     90|   punto|   150000|                 11|  diesel|      fiat|               ja|2016-03-07 00:00:00|           0|     66115|2016-03-07 18:57:08|\n",
      "|   52|2016-04-04 10:57:36|Verkaufe_meinen_k...|privat|  Angebot| 1400|control|       null|              2016|manuell|     55|  andere|     5000|                  1|    null|   hyundai|             null|2016-04-04 00:00:00|           0|     34454|2016-04-06 12:45:43|\n",
      "|   58|2016-03-10 20:53:19|Seat_inca_1.9SDI_...|privat|  Angebot| 2399|   test|       null|              2018|manuell|     64|  andere|   125000|                  3|    null|      seat|             nein|2016-03-10 00:00:00|           0|     33397|2016-03-25 10:17:37|\n",
      "|   66|2016-03-28 17:41:27|Opel_Astra_1.4_mi...|privat|  Angebot|10900|   test|       null|              2017|manuell|    101|   astra|    50000|                  3|    null|      opel|             nein|2016-03-28 00:00:00|           0|     63607|2016-04-06 23:15:52|\n",
      "|   72|2016-03-07 08:55:18|        BMW_520i_E39|privat|  Angebot| 2300|control|       null|              1997|manuell|    150|     5er|   150000|                  3|    null|       bmw|             nein|2016-03-07 00:00:00|           0|     79341|2016-03-22 05:15:22|\n",
      "|   78|2016-03-31 22:48:06|Golf_4_TDi_1_9.__...|privat|  Angebot|  800|   test|       null|              2000|manuell|     90|    golf|   150000|                  2|  diesel|volkswagen|             null|2016-03-31 00:00:00|           0|     32584|2016-04-06 19:15:22|\n",
      "|   81|2016-03-17 18:52:56| Opel_Astra_F_Cabrio|privat|  Angebot|  150|control|       null|              2016|manuell|     75|   astra|   150000|                  3|  benzin|      opel|               ja|2016-03-17 00:00:00|           0|     78315|2016-04-05 03:45:22|\n",
      "|   94|2016-03-16 07:56:19|FORD_KA___TÜV_ABG...|privat|  Angebot|  250|control|       null|              2000|   null|     60|      ka|   150000|                  0|    null|      ford|             null|2016-03-16 00:00:00|           0|     51427|2016-03-21 09:47:08|\n",
      "|   96|2016-03-28 16:37:43|unfall_Opel_insig...|privat|  Angebot| 8390|   test|       null|              2009|   null|      0|insignia|   150000|                  0|    null|      opel|             null|2016-03-28 00:00:00|           0|     29221|2016-03-30 07:44:59|\n",
      "|  111|2016-03-16 23:25:21|     Honda_Civic_EG4|privat|  Angebot|  900|   test|       null|              1995|manuell|     90|   civic|   150000|                  3|  benzin|     honda|             null|2016-03-16 00:00:00|           0|     35789|2016-03-19 17:19:00|\n",
      "|  115|2016-03-19 18:40:12|     Golf_IV_1.4_16V|privat|  Angebot|    0|   test|       null|              2017|manuell|      0|    golf|     5000|                 12|  benzin|volkswagen|             null|2016-03-19 00:00:00|           0|     21698|2016-04-01 08:47:05|\n",
      "+-----+-------------------+--------------------+------+---------+-----+-------+-----------+------------------+-------+-------+--------+---------+-------------------+--------+----------+-----------------+-------------------+------------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.filter(\"vehicleType is NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9bd743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv=df_csv.drop('nrOfPictures','seller','lastSeen','dateCreated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ac01de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'dateCrawled',\n",
       " 'name',\n",
       " 'offerType',\n",
       " 'price',\n",
       " 'abtest',\n",
       " 'vehicleType',\n",
       " 'yearOfRegistration',\n",
       " 'gearbox',\n",
       " 'powerPS',\n",
       " 'model',\n",
       " 'kilometer',\n",
       " 'monthOfRegistration',\n",
       " 'fuelType',\n",
       " 'brand',\n",
       " 'notRepairedDamage',\n",
       " 'postalCode']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91dff2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|        brand|\n",
      "+-------------+\n",
      "|       jaguar|\n",
      "|         nein|\n",
      "|     daihatsu|\n",
      "|   mitsubishi|\n",
      "|         null|\n",
      "|         lada|\n",
      "|       toyota|\n",
      "|         seat|\n",
      "|         saab|\n",
      "|   land_rover|\n",
      "|      peugeot|\n",
      "|     chrysler|\n",
      "|      citroen|\n",
      "|         audi|\n",
      "|mercedes_benz|\n",
      "|          bmw|\n",
      "|         jeep|\n",
      "|       lancia|\n",
      "|        skoda|\n",
      "|        rover|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.select('brand').distinct().show() #Distinct Model of Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "224a0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1be011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = df_csv.withColumn('dateCrawled', to_timestamp(df_csv[\"dateCrawled\"], \"yyyy-MM-dd HH:mm:ss\")) \n",
    "#Changing the car  price to Given Format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35685b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- dateCrawled: timestamp (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offerType: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- abtest: string (nullable = true)\n",
      " |-- vehicleType: string (nullable = true)\n",
      " |-- yearOfRegistration: string (nullable = true)\n",
      " |-- gearbox: string (nullable = true)\n",
      " |-- powerPS: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- kilometer: integer (nullable = true)\n",
      " |-- monthOfRegistration: string (nullable = true)\n",
      " |-- fuelType: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- notRepairedDamage: string (nullable = true)\n",
      " |-- postalCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0ceefaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|        dateCrawled|\n",
      "+-------------------+\n",
      "|2016-03-24 11:52:17|\n",
      "|2016-03-24 10:58:45|\n",
      "|2016-03-14 12:52:21|\n",
      "|2016-03-17 16:54:04|\n",
      "|2016-03-31 17:25:20|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.select('dateCrawled').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8184bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp, year\n",
    "df_csv = df_csv.withColumn(\"dateCrawled\", year(df_csv[\"dateCrawled\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a761b72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|dateCrawled|\n",
      "+-----------+\n",
      "|       2016|\n",
      "|       2016|\n",
      "|       2016|\n",
      "|       2016|\n",
      "|       2016|\n",
      "+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.select('dateCrawled').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d15de65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- dateCrawled: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offerType: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- abtest: string (nullable = true)\n",
      " |-- vehicleType: string (nullable = true)\n",
      " |-- yearOfRegistration: string (nullable = true)\n",
      " |-- gearbox: string (nullable = true)\n",
      " |-- powerPS: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- kilometer: integer (nullable = true)\n",
      " |-- monthOfRegistration: string (nullable = true)\n",
      " |-- fuelType: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- notRepairedDamage: string (nullable = true)\n",
      " |-- postalCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61b2c143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|yearOfRegistration|\n",
      "+------------------+\n",
      "|              1993|\n",
      "|              2011|\n",
      "|              2004|\n",
      "|              2001|\n",
      "|              2008|\n",
      "|              1995|\n",
      "|              2004|\n",
      "|              1980|\n",
      "|              2014|\n",
      "|              1998|\n",
      "+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.select('yearOfRegistration').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "218b5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "df_csv = df_csv.withColumn('yearOfRegistration', col('yearOfRegistration').cast(\"int\"))\n",
    "#Converting year of Registeration to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a91fce41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- dateCrawled: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offerType: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- abtest: string (nullable = true)\n",
      " |-- vehicleType: string (nullable = true)\n",
      " |-- yearOfRegistration: integer (nullable = true)\n",
      " |-- gearbox: string (nullable = true)\n",
      " |-- powerPS: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- kilometer: integer (nullable = true)\n",
      " |-- monthOfRegistration: string (nullable = true)\n",
      " |-- fuelType: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- notRepairedDamage: string (nullable = true)\n",
      " |-- postalCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82c2d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = df_csv.withColumn('Price', col('Price').cast(\"float\")) #Converting Thr Price To float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9833e42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- dateCrawled: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offerType: string (nullable = true)\n",
      " |-- Price: float (nullable = true)\n",
      " |-- abtest: string (nullable = true)\n",
      " |-- vehicleType: string (nullable = true)\n",
      " |-- yearOfRegistration: integer (nullable = true)\n",
      " |-- gearbox: string (nullable = true)\n",
      " |-- powerPS: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- kilometer: integer (nullable = true)\n",
      " |-- monthOfRegistration: string (nullable = true)\n",
      " |-- fuelType: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- notRepairedDamage: string (nullable = true)\n",
      " |-- postalCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3796afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = df_csv.withColumn('monthOfRegistration', col('monthOfRegistration').cast(\"int\")) #ConvertingThe Month Of registeration to int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fc5c0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- dateCrawled: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offerType: string (nullable = true)\n",
      " |-- Price: float (nullable = true)\n",
      " |-- abtest: string (nullable = true)\n",
      " |-- vehicleType: string (nullable = true)\n",
      " |-- yearOfRegistration: integer (nullable = true)\n",
      " |-- gearbox: string (nullable = true)\n",
      " |-- powerPS: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- kilometer: integer (nullable = true)\n",
      " |-- monthOfRegistration: integer (nullable = true)\n",
      " |-- fuelType: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- notRepairedDamage: string (nullable = true)\n",
      " |-- postalCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46658560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between value2 and value3: -0.0028176063434703284\n"
     ]
    }
   ],
   "source": [
    "correlation_value2_value3 = df_csv.stat.corr(\"monthOfRegistration\", \"Price\") #finding  the Correlation between MonthofRegisterationand price\n",
    "print(f\"Correlation between value2 and value3: {correlation_value2_value3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1adca635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between value2 and value3: 0.00013600453977892399\n"
     ]
    }
   ],
   "source": [
    "correlation_value2_value3 = df_csv.stat.corr(\"dateCrawled\", \"Price\") #finding the Correaltion betwwen the Datecrawled and price\n",
    "print(f\"Correlation between value2 and value3: {correlation_value2_value3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e806cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|monthOfRegistration|\n",
      "+-------------------+\n",
      "|                 12|\n",
      "|               null|\n",
      "|                  1|\n",
      "|                  6|\n",
      "|                  3|\n",
      "|                  5|\n",
      "|                  9|\n",
      "|                  4|\n",
      "|                  8|\n",
      "|                  7|\n",
      "|                 10|\n",
      "|                 11|\n",
      "|                  2|\n",
      "|                  0|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.select(\"monthOfRegistration\").distinct().show() #finding the Distict value for Month of Registeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db8e3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv=df_csv.drop('offerType') #only two tyep agebot and Genuch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df57af83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'dateCrawled',\n",
       " 'name',\n",
       " 'Price',\n",
       " 'abtest',\n",
       " 'vehicleType',\n",
       " 'yearOfRegistration',\n",
       " 'gearbox',\n",
       " 'powerPS',\n",
       " 'model',\n",
       " 'kilometer',\n",
       " 'monthOfRegistration',\n",
       " 'fuelType',\n",
       " 'brand',\n",
       " 'notRepairedDamage',\n",
       " 'postalCode']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6aedbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10779\n"
     ]
    }
   ],
   "source": [
    "zero_count = df_csv.filter(col(\"Price\") == 0).count()\n",
    "print(zero_count) #filtering the columns where price is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b21073c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'dateCrawled',\n",
       " 'name',\n",
       " 'Price',\n",
       " 'abtest',\n",
       " 'vehicleType',\n",
       " 'yearOfRegistration',\n",
       " 'gearbox',\n",
       " 'powerPS',\n",
       " 'model',\n",
       " 'kilometer',\n",
       " 'monthOfRegistration',\n",
       " 'fuelType',\n",
       " 'brand',\n",
       " 'notRepairedDamage',\n",
       " 'postalCode']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "525404a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|             Column|NullCount|\n",
      "+-------------------+---------+\n",
      "|              index|        0|\n",
      "|        dateCrawled|      296|\n",
      "|               name|        0|\n",
      "|              Price|      297|\n",
      "|             abtest|       30|\n",
      "|        vehicleType|    37871|\n",
      "| yearOfRegistration|      297|\n",
      "|            gearbox|    20211|\n",
      "|            powerPS|       15|\n",
      "|              model|    20485|\n",
      "|          kilometer|        1|\n",
      "|monthOfRegistration|      297|\n",
      "|           fuelType|    33388|\n",
      "|              brand|       64|\n",
      "|  notRepairedDamage|    72061|\n",
      "|         postalCode|        1|\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "df=df_csv\n",
    "# Get the list of columns\n",
    "columns = df.columns\n",
    "\n",
    "# Create a dictionary to store the null count for each column\n",
    "null_counts = {col_name: df.filter(col(col_name).isNull()).count() for col_name in columns}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better display\n",
    "null_counts_df = spark.createDataFrame([(k, v) for k, v in null_counts.items()], [\"Column\", \"NullCount\"])\n",
    "\n",
    "# Show the null counts\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1e7a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             Price|\n",
      "+-------+------------------+\n",
      "|  count|            371527|\n",
      "|   mean|17295.124128259857|\n",
      "| stddev|3587958.5758335786|\n",
      "|    min|               0.0|\n",
      "|    max|      2.14748365E9|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Price').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56df7762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th percentile: 250.0\n",
      "95th percentile: 19500.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the 5th and 95th percentiles\n",
    "quantiles = df.approxQuantile(\"price\", [0.05, 0.95], 0.01)\n",
    "\n",
    "# Extract the 5th and 95th percentiles\n",
    "quantile_05 = quantiles[0]\n",
    "quantile_95 = quantiles[1]\n",
    "\n",
    "print(f\"5th percentile: {quantile_05}\")\n",
    "print(f\"95th percentile: {quantile_95}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5ad24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy=df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79c489ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.filter(col(\"price\") != 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3560e315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|             Column|NullCount|\n",
      "+-------------------+---------+\n",
      "|              index|        0|\n",
      "|        dateCrawled|        0|\n",
      "|               name|        0|\n",
      "|              Price|        0|\n",
      "|             abtest|        0|\n",
      "|        vehicleType|    34127|\n",
      "| yearOfRegistration|        0|\n",
      "|            gearbox|    17729|\n",
      "|            powerPS|        0|\n",
      "|              model|    18300|\n",
      "|          kilometer|        0|\n",
      "|monthOfRegistration|        0|\n",
      "|           fuelType|    29948|\n",
      "|              brand|        0|\n",
      "|  notRepairedDamage|    66769|\n",
      "|         postalCode|        0|\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=df_copy\n",
    "# Get the list of columns\n",
    "columns = df.columns\n",
    "\n",
    "# Create a dictionary to store the null count for each column\n",
    "null_counts = {col_name: df.filter(col(col_name).isNull()).count() for col_name in columns}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better display\n",
    "null_counts_df = spark.createDataFrame([(k, v) for k, v in null_counts.items()], [\"Column\", \"NullCount\"])\n",
    "\n",
    "# Show the null counts\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5a74876",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_row = df_copy.groupBy(\"vehicleType\").count().orderBy(col(\"count\").desc()).first()\n",
    "most_common = most_common_row[\"vehicleType\"]\n",
    "df_VehicleCopy = df_copy.fillna({\"vehicleType\": most_common}) #imputing the data with the Mode for the vehicleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88f6490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|             Column|NullCount|\n",
      "+-------------------+---------+\n",
      "|              index|        0|\n",
      "|        dateCrawled|        0|\n",
      "|               name|        0|\n",
      "|              Price|        0|\n",
      "|             abtest|        0|\n",
      "|        vehicleType|        0|\n",
      "| yearOfRegistration|        0|\n",
      "|            gearbox|    17729|\n",
      "|            powerPS|        0|\n",
      "|              model|    18300|\n",
      "|          kilometer|        0|\n",
      "|monthOfRegistration|        0|\n",
      "|           fuelType|    29948|\n",
      "|              brand|        0|\n",
      "|  notRepairedDamage|    66769|\n",
      "|         postalCode|        0|\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df_VehicleCopy\n",
    "# Get the list of columns\n",
    "columns = df.columns\n",
    "\n",
    "# Create a dictionary to store the null count for each column\n",
    "null_counts = {col_name: df.filter(col(col_name).isNull()).count() for col_name in columns}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better display\n",
    "null_counts_df = spark.createDataFrame([(k, v) for k, v in null_counts.items()], [\"Column\", \"NullCount\"])\n",
    "\n",
    "# Show the null counts\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "aa383aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|vehicleType| count|\n",
      "+-----------+------+\n",
      "|  limousine|127969|\n",
      "| kleinwagen| 78209|\n",
      "|      kombi| 66098|\n",
      "|        bus| 29769|\n",
      "|     cabrio| 22560|\n",
      "|      coupe| 18487|\n",
      "|        suv| 14501|\n",
      "|     andere|  3155|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts = df_VehicleCopy.groupBy(\"vehicleType\").count()\n",
    "\n",
    "# Step 2: Sort by count in descending order\n",
    "sorted_value_counts = value_counts.orderBy(col(\"count\").desc())\n",
    "sorted_value_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edaf2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_row =df_VehicleCopy.groupBy(\"gearbox\").count().orderBy(col(\"count\").desc()).first()\n",
    "most_common = most_common_row[\"gearbox\"]\n",
    "\n",
    "# Step 2: Replace missing values in 'gearbox' column with the most common value\n",
    "df_VehicleCopy = df_VehicleCopy.fillna({\"gearbox\": most_common})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "321d08e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|             Column|NullCount|\n",
      "+-------------------+---------+\n",
      "|              index|        0|\n",
      "|        dateCrawled|        0|\n",
      "|               name|        0|\n",
      "|              Price|        0|\n",
      "|             abtest|        0|\n",
      "|        vehicleType|        0|\n",
      "| yearOfRegistration|        0|\n",
      "|            gearbox|        0|\n",
      "|            powerPS|        0|\n",
      "|              model|    18300|\n",
      "|          kilometer|        0|\n",
      "|monthOfRegistration|        0|\n",
      "|           fuelType|    29948|\n",
      "|              brand|        0|\n",
      "|  notRepairedDamage|    66769|\n",
      "|         postalCode|        0|\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df_VehicleCopy\n",
    "# Get the list of columns\n",
    "columns = df.columns\n",
    "\n",
    "# Create a dictionary to store the null count for each column\n",
    "null_counts = {col_name: df.filter(col(col_name).isNull()).count() for col_name in columns}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better display\n",
    "null_counts_df = spark.createDataFrame([(k, v) for k, v in null_counts.items()], [\"Column\", \"NullCount\"])\n",
    "\n",
    "# Show the null counts\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d55090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_row =df_VehicleCopy.groupBy(\"fuelType\").count().orderBy(col(\"count\").desc()).first()\n",
    "most_common = most_common_row[\"fuelType\"]\n",
    "\n",
    "# Step 2: Replace missing values in 'gearbox' column with the most common value\n",
    "df_VehicleCopy = df_VehicleCopy.fillna({\"fuelType\": most_common})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "966cb2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|             Column|NullCount|\n",
      "+-------------------+---------+\n",
      "|              index|        0|\n",
      "|        dateCrawled|        0|\n",
      "|               name|        0|\n",
      "|              Price|        0|\n",
      "|             abtest|        0|\n",
      "|        vehicleType|        0|\n",
      "| yearOfRegistration|        0|\n",
      "|            gearbox|        0|\n",
      "|            powerPS|        0|\n",
      "|              model|    18300|\n",
      "|          kilometer|        0|\n",
      "|monthOfRegistration|        0|\n",
      "|           fuelType|        0|\n",
      "|              brand|        0|\n",
      "|  notRepairedDamage|    66769|\n",
      "|         postalCode|        0|\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df_VehicleCopy\n",
    "# Get the list of columns\n",
    "columns = df.columns\n",
    "\n",
    "# Create a dictionary to store the null count for each column\n",
    "null_counts = {col_name: df.filter(col(col_name).isNull()).count() for col_name in columns}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better display\n",
    "null_counts_df = spark.createDataFrame([(k, v) for k, v in null_counts.items()], [\"Column\", \"NullCount\"])\n",
    "\n",
    "# Show the null counts\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09aa50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_row =df_VehicleCopy.groupBy(\"notRepairedDamage\").count().orderBy(col(\"count\").desc()).first()\n",
    "most_common = most_common_row[\"notRepairedDamage\"]\n",
    "\n",
    "# Step 2: Replace missing values in 'gearbox' column with the most common value\n",
    "df_VehicleCopy = df_VehicleCopy.fillna({\"notRepairedDamage\": most_common})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfae1626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|             Column|NullCount|\n",
      "+-------------------+---------+\n",
      "|              index|        0|\n",
      "|        dateCrawled|        0|\n",
      "|               name|        0|\n",
      "|              Price|        0|\n",
      "|             abtest|        0|\n",
      "|        vehicleType|        0|\n",
      "| yearOfRegistration|        0|\n",
      "|            gearbox|        0|\n",
      "|            powerPS|        0|\n",
      "|              model|    18300|\n",
      "|          kilometer|        0|\n",
      "|monthOfRegistration|        0|\n",
      "|           fuelType|        0|\n",
      "|              brand|        0|\n",
      "|  notRepairedDamage|        0|\n",
      "|         postalCode|        0|\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df_VehicleCopy\n",
    "# Get the list of columns\n",
    "columns = df.columns\n",
    "\n",
    "# Create a dictionary to store the null count for each column\n",
    "null_counts = {col_name: df.filter(col(col_name).isNull()).count() for col_name in columns}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better display\n",
    "null_counts_df = spark.createDataFrame([(k, v) for k, v in null_counts.items()], [\"Column\", \"NullCount\"])\n",
    "\n",
    "# Show the null counts\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d73be87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'dateCrawled',\n",
       " 'name',\n",
       " 'Price',\n",
       " 'abtest',\n",
       " 'vehicleType',\n",
       " 'yearOfRegistration',\n",
       " 'gearbox',\n",
       " 'powerPS',\n",
       " 'model',\n",
       " 'kilometer',\n",
       " 'monthOfRegistration',\n",
       " 'fuelType',\n",
       " 'brand',\n",
       " 'notRepairedDamage',\n",
       " 'postalCode']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VehicleCopy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3775914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day2=df_VehicleCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6deaa6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_day2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa2f0cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           powerPS|\n",
      "+-------+------------------+\n",
      "|  count|            360748|\n",
      "|   mean|116.57623604288867|\n",
      "| stddev|190.60860977764153|\n",
      "|    min|                 0|\n",
      "|    max|              9999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "df.select('powerPS').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13c14a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn(\"powerPS\", col(\"powerPS\").cast(\"int\")) #converting the power ps to the int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2e8c0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th percentile: 0.0\n",
      "95th percentile: 231.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Calculate the 5th and 95th percentiles\n",
    "quantiles = df.approxQuantile(\"powerPS\", [0.05, 0.95], 0.01)\n",
    "\n",
    "# Extract the 5th and 95th percentiles\n",
    "quantile_05 = quantiles[0]\n",
    "quantile_95 = quantiles[1]\n",
    "\n",
    "print(f\"5th percentile: {quantile_05}\")\n",
    "print(f\"95th percentile: {quantile_95}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "653a42a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+\n",
      "|index|dateCrawled|                name|  Price|abtest|vehicleType|yearOfRegistration|  gearbox|powerPS|model|kilometer|monthOfRegistration|fuelType|     brand|notRepairedDamage|postalCode|\n",
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+\n",
      "|    0|       2016|          Golf_3_1.6|  480.0|  test|  limousine|              1993|  manuell|     40| golf|   150000|                  0|  benzin|volkswagen|             nein|     70435|\n",
      "|    1|       2016|A5_Sportback_2.7_Tdi|18300.0|  test|      coupe|              2011|  manuell|    190| null|   125000|                  5|  diesel|      audi|               ja|     66954|\n",
      "|    2|       2016|\"Jeep_Grand_Chero...| 9800.0|  test|        suv|              2004|automatik|    163|grand|   125000|                  8|  diesel|      jeep|             nein|     90480|\n",
      "|    3|       2016|  GOLF_4_1_4__3TÜRER| 1500.0|  test| kleinwagen|              2001|  manuell|     75| golf|   150000|                  6|  benzin|volkswagen|             nein|     91074|\n",
      "|    4|       2016|Skoda_Fabia_1.4_T...| 3600.0|  test| kleinwagen|              2008|  manuell|     69|fabia|    90000|                  7|  diesel|     skoda|             nein|     60437|\n",
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_imputed = df.withColumn(\"powerPS\", \n",
    "                           when(col(\"powerPS\") < 40, 40)\n",
    "                           .when(col(\"powerPS\") > 15000, 15000)\n",
    "                           .otherwise(col(\"powerPS\")))\n",
    "df_imputed.show(5) #imputing the data for powerps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87ff8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "300255f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('model').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3b58e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VehicleCopy=df\n",
    "most_common_row =df_VehicleCopy.groupBy(\"model\").count().orderBy(col(\"count\").desc()).first()\n",
    "most_common = most_common_row[\"model\"]\n",
    "\n",
    "# Step 2: Replace missing values in 'gearbox' column with the most common value\n",
    "df_VehicleCopy = df_VehicleCopy.fillna({\"model\": most_common})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afcfbaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_VehicleCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6eaf44bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|             Column|NullCount|\n",
      "+-------------------+---------+\n",
      "|              index|        0|\n",
      "|        dateCrawled|        0|\n",
      "|               name|        0|\n",
      "|              Price|        0|\n",
      "|             abtest|        0|\n",
      "|        vehicleType|        0|\n",
      "| yearOfRegistration|        0|\n",
      "|            gearbox|        0|\n",
      "|            powerPS|        0|\n",
      "|              model|        0|\n",
      "|          kilometer|        0|\n",
      "|monthOfRegistration|        0|\n",
      "|           fuelType|        0|\n",
      "|              brand|        0|\n",
      "|  notRepairedDamage|        0|\n",
      "|         postalCode|        0|\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the list of columns\n",
    "columns = df.columns\n",
    "\n",
    "# Create a dictionary to store the null count for each column\n",
    "null_counts = {col_name: df.filter(col(col_name).isNull()).count() for col_name in columns}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better display\n",
    "null_counts_df = spark.createDataFrame([(k, v) for k, v in null_counts.items()], [\"Column\", \"NullCount\"])\n",
    "\n",
    "# Show the null counts\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b527d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col\n",
    "df = df.withColumn(\"monthOfRegistration\", when(col(\"monthOfRegistration\") == 0, 1).otherwise(col(\"monthOfRegistration\")))\n",
    "#converting the month of registeration from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "774bd26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "zero_count = df.filter(col(\"monthOfRegistration\") == 0).count()\n",
    "print(zero_count) #printing the number of time where monthofregisteration is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff02fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"postalCode\", col(\"postalCode\").cast(\"int\")) #converting the postalcode to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1106b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8146"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('postalCode').distinct().count() #calculating the distinct value for postalcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a366beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|  gearbox|\n",
      "+---------+\n",
      "|automatik|\n",
      "|  manuell|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('gearbox').distinct().show() #getting distinct value for gearbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d27c96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+\n",
      "|index|dateCrawled|                name|  Price|abtest|vehicleType|yearOfRegistration|  gearbox|powerPS|model|kilometer|monthOfRegistration|fuelType|     brand|notRepairedDamage|postalCode|\n",
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+\n",
      "|    0|       2016|          Golf_3_1.6|  480.0|  test|  limousine|              1993|   Manual|     40| golf|   150000|                  1|  benzin|volkswagen|             nein|     70435|\n",
      "|    1|       2016|A5_Sportback_2.7_Tdi|18300.0|  test|      coupe|              2011|   Manual|    190| golf|   125000|                  5|  diesel|      audi|               ja|     66954|\n",
      "|    2|       2016|\"Jeep_Grand_Chero...| 9800.0|  test|        suv|              2004|Automatic|    163|grand|   125000|                  8|  diesel|      jeep|             nein|     90480|\n",
      "|    3|       2016|  GOLF_4_1_4__3TÜRER| 1500.0|  test| kleinwagen|              2001|   Manual|     75| golf|   150000|                  6|  benzin|volkswagen|             nein|     91074|\n",
      "|    4|       2016|Skoda_Fabia_1.4_T...| 3600.0|  test| kleinwagen|              2008|   Manual|     69|fabia|    90000|                  7|  diesel|     skoda|             nein|     60437|\n",
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename column values\n",
    "df_renamed = df.withColumn('gearbox', \n",
    "                           when(col('gearbox') == \"automatik\", \"Automatic\")\n",
    "                           .when(col('gearbox') == \"manuell\", \"Manual\")\n",
    "                          )\n",
    "df_renamed.show(5) #translating from german to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6da6ba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|  gearbox|\n",
      "+---------+\n",
      "|Automatic|\n",
      "|   Manual|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df_renamed\n",
    "df.select('gearbox').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd57e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|vehicleType|\n",
      "+-----------+\n",
      "|      coupe|\n",
      "| kleinwagen|\n",
      "|        bus|\n",
      "|     andere|\n",
      "|  limousine|\n",
      "|     cabrio|\n",
      "|        suv|\n",
      "|      kombi|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('vehicleType').distinct().show() #getting the distinct value for vehicleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a0f009bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed = df.withColumn('vehicleType', \n",
    "                           when(col('vehicleType') == \"coupe\", \"coupe\")\n",
    "                           .when(col('vehicleType') == \"kleinwagen\", \"small_car\")\n",
    "                           .when(col( 'vehicleType' ) == \"limousine\", \"sedan\")\n",
    "                           .when(col('vehicleType') == \"cabrio\", \"convertible\")\n",
    "                           .when(col('vehicleType') == \"bus\", \"bus\")\n",
    "                           .when(col('vehicleType') == \"kombi\", \"station_wagon\")\n",
    "                           .when(col('vehicleType') == \"andere\", \"Others\")\n",
    "                           .when(col('vehicleType') == \"suv\", \"suv\")\n",
    "                          )\n",
    "\n",
    "#translating the german to english                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5dc4ad63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|  vehicleType|\n",
      "+-------------+\n",
      "|        coupe|\n",
      "|          bus|\n",
      "|station_wagon|\n",
      "|    small_car|\n",
      "|          suv|\n",
      "|  convertible|\n",
      "|       Others|\n",
      "|        sedan|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df_renamed\n",
    "df.select('vehicleType').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d1e6a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|fuelType|\n",
      "+--------+\n",
      "|  benzin|\n",
      "| elektro|\n",
      "|  andere|\n",
      "|  diesel|\n",
      "|     cng|\n",
      "|  hybrid|\n",
      "|     lpg|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('fuelType').distinct().show() #getting the Distinct fuel type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73c567a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed = df.withColumn('fuelType', \n",
    "                           when(col('fuelType') == \"benzin\", \"Petrol\")\n",
    "                           .when(col('fuelType') == \"elektro\", \"Electric\")\n",
    "                           .when(col( 'fuelType' ) == \"lpg\", \"LPG\")\n",
    "                           .when(col('fuelType') == \"diesel\", \"Diesel\")\n",
    "                           .when(col('fuelType') == \"cng\", \"CNG\")\n",
    "                           .when(col('fuelType') == \"hybrid\", \"Hybrid\")\n",
    "                           .when(col('fuelType') == \"andere\", \"Others\")\n",
    "                          )\n",
    "#translating the fueltype from german to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ebd62d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|fuelType|\n",
      "+--------+\n",
      "|  Diesel|\n",
      "|  Hybrid|\n",
      "|     CNG|\n",
      "|  Others|\n",
      "|Electric|\n",
      "|     LPG|\n",
      "|  Petrol|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df_renamed\n",
    "df.select('fuelType').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "163437bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = spark.createDataFrame(df_VehicleCopy, df_VehicleCopy.columns)\n",
    "#df_VehicleCopy=df\n",
    "#pandas_df = df_VehicleCopy.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f5c4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+\n",
      "|index|dateCrawled|                name|  Price|abtest|vehicleType|yearOfRegistration|  gearbox|powerPS|model|kilometer|monthOfRegistration|fuelType|     brand|notRepairedDamage|postalCode|\n",
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+\n",
      "|    0|       2016|          Golf_3_1.6|  480.0|  test|      sedan|              1993|   Manual|     40| golf|   150000|                  1|  Petrol|volkswagen|             nein|     70435|\n",
      "|    1|       2016|A5_Sportback_2.7_Tdi|18300.0|  test|      coupe|              2011|   Manual|    190| golf|   125000|                  5|  Diesel|      audi|               ja|     66954|\n",
      "|    2|       2016|\"Jeep_Grand_Chero...| 9800.0|  test|        suv|              2004|Automatic|    163|grand|   125000|                  8|  Diesel|      jeep|             nein|     90480|\n",
      "|    3|       2016|  GOLF_4_1_4__3TÜRER| 1500.0|  test|  small_car|              2001|   Manual|     75| golf|   150000|                  6|  Petrol|volkswagen|             nein|     91074|\n",
      "|    4|       2016|Skoda_Fabia_1.4_T...| 3600.0|  test|  small_car|              2008|   Manual|     69|fabia|    90000|                  7|  Diesel|     skoda|             nein|     60437|\n",
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_VehicleCopy.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da2799c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|notRepairedDamage|\n",
      "+-----------------+\n",
      "|             nein|\n",
      "|               ja|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('notRepairedDamage').distinct().show() #finding the diatinct value for not repaird damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bde907c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed = df.withColumn('notRepairedDamage', \n",
    "                           when(col('notRepairedDamage') == \"nein\", \"No\")\n",
    "                           .when(col('notRepairedDamage') == \"ja\", \"Yes\")\n",
    "                          )\n",
    "#translating the german to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9630c2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|notRepairedDamage|\n",
      "+-----------------+\n",
      "|               No|\n",
      "|              Yes|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df_renamed\n",
    "df.select('notRepairedDamage').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1cf33a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'dateCrawled',\n",
       " 'name',\n",
       " 'Price',\n",
       " 'abtest',\n",
       " 'vehicleType',\n",
       " 'yearOfRegistration',\n",
       " 'gearbox',\n",
       " 'powerPS',\n",
       " 'model',\n",
       " 'kilometer',\n",
       " 'monthOfRegistration',\n",
       " 'fuelType',\n",
       " 'brand',\n",
       " 'notRepairedDamage',\n",
       " 'postalCode']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c60b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_difference = df.withColumn(\"Car_age\", col('dateCrawled') - col(\"yearOfRegistration\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3dda9060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Car_age|\n",
      "+-------+\n",
      "|     23|\n",
      "|      5|\n",
      "|     12|\n",
      "|     15|\n",
      "|      8|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_with_difference.select('Car_age').show(5)\n",
    " # this contains the Index and name column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ddf512cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|dateCrawled|\n",
      "+-----------+\n",
      "|       2016|\n",
      "|       2016|\n",
      "+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('dateCrawled').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8b06f3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[index: string, dateCrawled: date, name: string, Price: float, abtest: string, vehicleType: string, yearOfRegistration: int, gearbox: string, powerPS: int, model: string, kilometer: int, monthOfRegistration: int, fuelType: string, brand: string, notRepairedDamage: string, postalCode: int, Car_age: int]>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "df = df.withColumn('dateString', expr(\"concat(dateCrawled, '-01-01')\"))\n",
    "\n",
    "# Convert the date string to DateType\n",
    "df = df.withColumn('dateCrawled', col('dateString').cast('date'))\n",
    "\n",
    "# Drop the intermediate 'dateString' column\n",
    "df = df.drop('dateString')\n",
    "\n",
    "# Show the DataFrame with the new 'dateCrawled' colum\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "97a8ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|dateCrawled|\n",
      "+-----------+\n",
      "| 2016-01-01|\n",
      "| 2016-01-01|\n",
      "+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('dateCrawled').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e0a5984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[index: string, dateCrawled: date, name: string, Price: float, abtest: string, vehicleType: string, yearOfRegistration: date, gearbox: string, powerPS: int, model: string, kilometer: int, monthOfRegistration: int, fuelType: string, brand: string, notRepairedDamage: string, postalCode: int, Car_age: int]>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn('dateString', expr(\"concat(yearOfRegistration, '-01-01')\"))\n",
    "\n",
    "# Convert the date string to DateType\n",
    "df = df.withColumn('yearOfRegistration', col('dateString').cast('date'))\n",
    "\n",
    "# Drop the intermediate 'dateString' column\n",
    "df = df.drop('dateString')\n",
    "\n",
    "# Show the DataFrame with the new 'dateCrawled' colum\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "15fef28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|yearOfRegistration|\n",
      "+------------------+\n",
      "|        1993-01-01|\n",
      "|        2011-01-01|\n",
      "+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('yearOfRegistration').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cce637cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, datediff\n",
    "df_dateDiff=df\n",
    "df_dateDiff = df_dateDiff.withColumn('Car_age', datediff(col('dateCrawled'), col('yearOfRegistration')))\n",
    "#calculating the date difference between datecrawled and yearofregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd2a5f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Car_age|\n",
      "+-------+\n",
      "|   8400|\n",
      "|   1826|\n",
      "|   4383|\n",
      "|   5478|\n",
      "|   2922|\n",
      "|   7670|\n",
      "|   4383|\n",
      "|    730|\n",
      "|   6574|\n",
      "|   4383|\n",
      "+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dateDiff.select('Car_age').show(10) #car age comes out to in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17f68b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|           Car_age|\n",
      "+------------------+\n",
      "|23.013698630136986|\n",
      "| 5.002739726027397|\n",
      "|12.008219178082191|\n",
      "|15.008219178082191|\n",
      "| 8.005479452054795|\n",
      "|21.013698630136986|\n",
      "|12.008219178082191|\n",
      "|               2.0|\n",
      "| 18.01095890410959|\n",
      "|12.008219178082191|\n",
      "+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dateDiff = df_dateDiff.withColumn('Car_age', col('Car_age') / 365)\n",
    "df_dateDiff.select('Car_age').show(10)\n",
    "#car age is converted to the year format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "46d63ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Car_age|\n",
      "+-------+\n",
      "|     23|\n",
      "|      5|\n",
      "|     12|\n",
      "|     15|\n",
      "|      8|\n",
      "|     21|\n",
      "|     12|\n",
      "|      2|\n",
      "|     18|\n",
      "|     12|\n",
      "+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dateDiff = df_dateDiff.withColumn('Car_age', col('Car_age').cast('integer'))\n",
    "df_dateDiff.select('Car_age').show(10) #converting float to integer datatype for car_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "14bdc510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin 1: (-7988.0, -7875.45): 19\n",
      "Bin 2: (-7875.45, -7762.9): 0\n",
      "Bin 3: (-7762.9, -7650.35): 0\n",
      "Bin 4: (-7650.35, -7537.8): 0\n",
      "Bin 5: (-7537.8, -7425.25): 1\n",
      "Bin 6: (-7425.25, -7312.7): 0\n",
      "Bin 7: (-7312.7, -7200.15): 0\n",
      "Bin 8: (-7200.15, -7087.6): 0\n",
      "Bin 9: (-7087.6, -6975.05): 4\n",
      "Bin 10: (-6975.05, -6862.5): 2\n",
      "Bin 11: (-6862.5, -6749.95): 0\n",
      "Bin 12: (-6749.95, -6637.4): 0\n",
      "Bin 13: (-6637.4, -6524.85): 0\n",
      "Bin 14: (-6524.85, -6412.3): 1\n",
      "Bin 15: (-6412.3, -6299.75): 0\n",
      "Bin 16: (-6299.75, -6187.2): 1\n",
      "Bin 17: (-6187.2, -6074.65): 0\n",
      "Bin 18: (-6074.65, -5962.1): 2\n",
      "Bin 19: (-5962.1, -5849.55): 0\n",
      "Bin 20: (-5849.55, -5737.0): 2\n",
      "Bin 21: (-5737.0, -5624.450000000001): 0\n",
      "Bin 22: (-5624.450000000001, -5511.9): 0\n",
      "Bin 23: (-5511.9, -5399.35): 1\n",
      "Bin 24: (-5399.35, -5286.8): 0\n",
      "Bin 25: (-5286.8, -5174.25): 0\n",
      "Bin 26: (-5174.25, -5061.700000000001): 1\n",
      "Bin 27: (-5061.700000000001, -4949.15): 4\n",
      "Bin 28: (-4949.15, -4836.6): 0\n",
      "Bin 29: (-4836.6, -4724.05): 0\n",
      "Bin 30: (-4724.05, -4611.5): 0\n",
      "Bin 31: (-4611.5, -4498.950000000001): 0\n",
      "Bin 32: (-4498.950000000001, -4386.4): 1\n",
      "Bin 33: (-4386.4, -4273.85): 0\n",
      "Bin 34: (-4273.85, -4161.3): 1\n",
      "Bin 35: (-4161.3, -4048.75): 0\n",
      "Bin 36: (-4048.75, -3936.2000000000003): 6\n",
      "Bin 37: (-3936.2000000000003, -3823.6500000000005): 3\n",
      "Bin 38: (-3823.6500000000005, -3711.1000000000004): 0\n",
      "Bin 39: (-3711.1000000000004, -3598.55): 0\n",
      "Bin 40: (-3598.55, -3486.0): 3\n",
      "Bin 41: (-3486.0, -3373.45): 0\n",
      "Bin 42: (-3373.45, -3260.9000000000005): 1\n",
      "Bin 43: (-3260.9000000000005, -3148.3500000000004): 0\n",
      "Bin 44: (-3148.3500000000004, -3035.8): 0\n",
      "Bin 45: (-3035.8, -2923.25): 17\n",
      "Bin 46: (-2923.25, -2810.7): 0\n",
      "Bin 47: (-2810.7, -2698.1500000000005): 1\n",
      "Bin 48: (-2698.1500000000005, -2585.6000000000004): 0\n",
      "Bin 49: (-2585.6000000000004, -2473.05): 2\n",
      "Bin 50: (-2473.05, -2360.5): 0\n",
      "Bin 51: (-2360.5, -2247.95): 0\n",
      "Bin 52: (-2247.95, -2135.4000000000005): 0\n",
      "Bin 53: (-2135.4000000000005, -2022.8500000000004): 1\n",
      "Bin 54: (-2022.8500000000004, -1910.3000000000002): 3\n",
      "Bin 55: (-1910.3000000000002, -1797.75): 0\n",
      "Bin 56: (-1797.75, -1685.1999999999998): 1\n",
      "Bin 57: (-1685.1999999999998, -1572.6500000000005): 1\n",
      "Bin 58: (-1572.6500000000005, -1460.1000000000004): 0\n",
      "Bin 59: (-1460.1000000000004, -1347.5500000000002): 0\n",
      "Bin 60: (-1347.5500000000002, -1235.0): 0\n",
      "Bin 61: (-1235.0, -1122.4499999999998): 1\n",
      "Bin 62: (-1122.4499999999998, -1009.9000000000005): 0\n",
      "Bin 63: (-1009.9000000000005, -897.3500000000004): 6\n",
      "Bin 64: (-897.3500000000004, -784.8000000000002): 1\n",
      "Bin 65: (-784.8000000000002, -672.25): 1\n",
      "Bin 66: (-672.25, -559.6999999999998): 0\n",
      "Bin 67: (-559.6999999999998, -447.15000000000055): 3\n",
      "Bin 68: (-447.15000000000055, -334.60000000000036): 0\n",
      "Bin 69: (-334.60000000000036, -222.05000000000018): 1\n",
      "Bin 70: (-222.05000000000018, -109.5): 2\n",
      "Bin 71: (-109.5, 3.050000000000182): 36877\n",
      "Bin 72: (3.050000000000182, 115.59999999999945): 323722\n",
      "Bin 73: (115.59999999999945, 228.14999999999964): 5\n",
      "Bin 74: (228.14999999999964, 340.6999999999989): 0\n",
      "Bin 75: (340.6999999999989, 453.25): 3\n",
      "Bin 76: (453.25, 565.7999999999993): 3\n",
      "Bin 77: (565.7999999999993, 678.3500000000004): 1\n",
      "Bin 78: (678.3500000000004, 790.8999999999996): 7\n",
      "Bin 79: (790.8999999999996, 903.4499999999989): 0\n",
      "Bin 80: (903.4499999999989, 1016): 36\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = 80\n",
    "\n",
    "# Compute histogram\n",
    "hist = df_dateDiff.select('Car_age').rdd.flatMap(lambda x: x).histogram(num_bins)\n",
    "\n",
    "# Display histogram\n",
    "for i in range(len(hist[0]) - 1):\n",
    "    print(f\"Bin {i+1}: ({hist[0][i]}, {hist[0][i+1]}): {hist[1][i]}\")\n",
    "    \n",
    "#plotting the histogram for the Car_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8792df92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|          stddev|\n",
      "+----------------+\n",
      "|82.1505593217502|\n",
      "+----------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|           Car_age|\n",
      "+-------+------------------+\n",
      "|  count|            360748|\n",
      "|   mean|11.548895627972989|\n",
      "| stddev|  82.1505593217502|\n",
      "|    min|             -7988|\n",
      "|    max|              1016|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import stddev_samp\n",
    "stddev_df = df_dateDiff.agg(stddev_samp('Car_age').alias('stddev'))\n",
    "\n",
    "# Show the result\n",
    "stddev_df.show()\n",
    "df_dateDiff.select('Car_age').describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2731f8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+-------+\n",
      "|index|dateCrawled|                name|  Price|abtest|vehicleType|yearOfRegistration|  gearbox|powerPS|model|kilometer|monthOfRegistration|fuelType|     brand|notRepairedDamage|postalCode|Car_age|\n",
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+-------+\n",
      "|    0| 2016-01-01|          Golf_3_1.6|  480.0|  test|      sedan|        1993-01-01|   Manual|     40| golf|   150000|                  1|  Petrol|volkswagen|               No|     70435|     23|\n",
      "|    1| 2016-01-01|A5_Sportback_2.7_Tdi|18300.0|  test|      coupe|        2011-01-01|   Manual|    190| golf|   125000|                  5|  Diesel|      audi|              Yes|     66954|      5|\n",
      "|    2| 2016-01-01|\"Jeep_Grand_Chero...| 9800.0|  test|        suv|        2004-01-01|Automatic|    163|grand|   125000|                  8|  Diesel|      jeep|               No|     90480|     12|\n",
      "|    3| 2016-01-01|  GOLF_4_1_4__3TÜRER| 1500.0|  test|  small_car|        2001-01-01|   Manual|     75| golf|   150000|                  6|  Petrol|volkswagen|               No|     91074|     15|\n",
      "|    4| 2016-01-01|Skoda_Fabia_1.4_T...| 3600.0|  test|  small_car|        2008-01-01|   Manual|     69|fabia|    90000|                  7|  Diesel|     skoda|               No|     60437|      8|\n",
      "+-----+-----------+--------------------+-------+------+-----------+------------------+---------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "df_imputed = df_dateDiff.withColumn(\"Car_age\", \n",
    "                           when(col(\"Car_age\") < 3, 3)\n",
    "                           .when(col(\"Car_age\") > 93, 93)\n",
    "                           .otherwise(col(\"Car_age\")))\n",
    "df_imputed.show(5)\n",
    "#imputing data for the Car_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "78e61168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|min_value|max_value|\n",
      "+---------+---------+\n",
      "|        3|       93|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "min_max_df = df_imputed.select(min(\"Car_age\").alias(\"min_value\"), max(\"Car_age\").alias(\"max_value\"))\n",
    "min_max_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "164a481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fb1ae7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- dateCrawled: date (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- Price: float (nullable = true)\n",
      " |-- abtest: string (nullable = true)\n",
      " |-- vehicleType: string (nullable = true)\n",
      " |-- yearOfRegistration: date (nullable = true)\n",
      " |-- gearbox: string (nullable = true)\n",
      " |-- powerPS: integer (nullable = true)\n",
      " |-- model: string (nullable = false)\n",
      " |-- kilometer: integer (nullable = true)\n",
      " |-- monthOfRegistration: integer (nullable = true)\n",
      " |-- fuelType: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- notRepairedDamage: string (nullable = true)\n",
      " |-- postalCode: integer (nullable = true)\n",
      " |-- Car_age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "17a2bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    " df_dropped=df.drop(*[ 'index','name'])\n",
    "#froppin the column for index and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef3bf44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dateCrawled: date (nullable = true)\n",
      " |-- Price: float (nullable = true)\n",
      " |-- abtest: string (nullable = true)\n",
      " |-- vehicleType: string (nullable = true)\n",
      " |-- yearOfRegistration: date (nullable = true)\n",
      " |-- gearbox: string (nullable = true)\n",
      " |-- powerPS: integer (nullable = true)\n",
      " |-- model: string (nullable = false)\n",
      " |-- kilometer: integer (nullable = true)\n",
      " |-- monthOfRegistration: integer (nullable = true)\n",
      " |-- fuelType: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- notRepairedDamage: string (nullable = true)\n",
      " |-- postalCode: integer (nullable = true)\n",
      " |-- Car_age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dropped.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f305b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "945ee4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|             Column|NullCount|\n",
      "+-------------------+---------+\n",
      "|              index|        0|\n",
      "|        dateCrawled|        0|\n",
      "|               name|        0|\n",
      "|              Price|        0|\n",
      "|             abtest|        0|\n",
      "|        vehicleType|        0|\n",
      "| yearOfRegistration|        0|\n",
      "|            gearbox|        0|\n",
      "|            powerPS|        0|\n",
      "|              model|        0|\n",
      "|          kilometer|        0|\n",
      "|monthOfRegistration|        0|\n",
      "|           fuelType|        0|\n",
      "|              brand|        0|\n",
      "|  notRepairedDamage|        0|\n",
      "|         postalCode|        0|\n",
      "|            Car_age|        0|\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns\n",
    "\n",
    "# Create a dictionary to store the null count for each column\n",
    "null_counts = {col_name: df.filter(col(col_name).isNull()).count() for col_name in columns}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better display\n",
    "null_counts_df = spark.createDataFrame([(k, v) for k, v in null_counts.items()], [\"Column\", \"NullCount\"])\n",
    "\n",
    "# Show the null counts\n",
    "null_counts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "23e117b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+----------+-----+------+-----------+------------------+-------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+-------+\n",
      "|index|dateCrawled|      name|Price|abtest|vehicleType|yearOfRegistration|gearbox|powerPS|model|kilometer|monthOfRegistration|fuelType|     brand|notRepairedDamage|postalCode|Car_age|\n",
      "+-----+-----------+----------+-----+------+-----------+------------------+-------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+-------+\n",
      "|    0| 2016-01-01|Golf_3_1.6|480.0|  test|      sedan|        1993-01-01| Manual|     40| golf|   150000|                  1|  Petrol|volkswagen|               No|     70435|     23|\n",
      "+-----+-----------+----------+-----+------+-----------+------------------+-------+-------+-----+---------+-------------------+--------+----------+-----------------+----------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "94c65acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Is Stored on Hive HDFS Automatically\n",
    "#tablename=\"Project_Autos.autos\"\n",
    "#df.write.mode(\"overwrite\").saveAsTable(tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29260923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_path = \"MainData\"  # Change this to your desired output path\n",
    "#df_VehicleCopy=df\n",
    "#pandas_df = df_VehicleCopy.toPandas()\n",
    "# Save DataFrame to CSV\n",
    "#df.write.csv(output_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22adf494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Secound Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "02c21681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleating columns for dateCrawled,name,yearOfRegistration\n",
    "#df2=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "25bd2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dropped=df2.drop(*[ 'index','dateCrawled','name','yearOfRegistration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0ffa648e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Price',\n",
       " 'abtest',\n",
       " 'vehicleType',\n",
       " 'gearbox',\n",
       " 'powerPS',\n",
       " 'model',\n",
       " 'kilometer',\n",
       " 'monthOfRegistration',\n",
       " 'fuelType',\n",
       " 'brand',\n",
       " 'notRepairedDamage',\n",
       " 'postalCode',\n",
       " 'Car_age']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_dropped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5feb1fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid filters were applied.\n",
      "+-------+-------+-------------+---------+-------+--------+---------+-------------------+--------+-------------+-----------------+----------+-------+\n",
      "|  Price| abtest|  vehicleType|  gearbox|powerPS|   model|kilometer|monthOfRegistration|fuelType|        brand|notRepairedDamage|postalCode|Car_age|\n",
      "+-------+-------+-------------+---------+-------+--------+---------+-------------------+--------+-------------+-----------------+----------+-------+\n",
      "|  480.0|   test|        sedan|   Manual|     40|    golf|   150000|                  1|  Petrol|   volkswagen|               No|     70435|     23|\n",
      "|18300.0|   test|        coupe|   Manual|    190|    golf|   125000|                  5|  Diesel|         audi|              Yes|     66954|      5|\n",
      "| 9800.0|   test|          suv|Automatic|    163|   grand|   125000|                  8|  Diesel|         jeep|               No|     90480|     12|\n",
      "| 1500.0|   test|    small_car|   Manual|     75|    golf|   150000|                  6|  Petrol|   volkswagen|               No|     91074|     15|\n",
      "| 3600.0|   test|    small_car|   Manual|     69|   fabia|    90000|                  7|  Diesel|        skoda|               No|     60437|      8|\n",
      "|  650.0|   test|        sedan|   Manual|    102|     3er|   150000|                 10|  Petrol|          bmw|              Yes|     33775|     21|\n",
      "| 2200.0|   test|  convertible|   Manual|    109| 2_reihe|   150000|                  8|  Petrol|      peugeot|               No|     67112|     12|\n",
      "|14500.0|control|          bus|   Manual|    125|   c_max|    30000|                  8|  Petrol|         ford|               No|     94505|      3|\n",
      "|  999.0|   test|    small_car|   Manual|    101|    golf|   150000|                  1|  Petrol|   volkswagen|               No|     27472|     18|\n",
      "| 2000.0|control|        sedan|   Manual|    105| 3_reihe|   150000|                 12|  Petrol|        mazda|               No|     96224|     12|\n",
      "| 2799.0|control|station_wagon|   Manual|    140|  passat|   150000|                 12|  Diesel|   volkswagen|              Yes|     57290|     11|\n",
      "|  999.0|control|station_wagon|   Manual|    115|  passat|   150000|                 11|  Petrol|   volkswagen|               No|     37269|     21|\n",
      "| 2500.0|control|station_wagon|   Manual|    131|  passat|   150000|                  2|  Petrol|   volkswagen|               No|     90762|     12|\n",
      "|17999.0|control|          suv|   Manual|    190|  navara|    70000|                  3|  Diesel|       nissan|               No|      4177|      5|\n",
      "|  450.0|   test|    small_car|   Manual|     40|      ka|     5000|                  1|  Petrol|         ford|               No|     24148|     93|\n",
      "|  300.0|   test|        sedan|   Manual|     60|    polo|   150000|                  1|  Petrol|   volkswagen|               No|     38871|      3|\n",
      "| 1750.0|control|    small_car|Automatic|     75|  twingo|   150000|                  2|  Petrol|      renault|               No|     65599|     12|\n",
      "| 7550.0|   test|          bus|   Manual|    136|   c_max|   150000|                  6|  Diesel|         ford|               No|     88361|      9|\n",
      "| 1850.0|   test|          bus|   Manual|    102|a_klasse|   150000|                  1|  Petrol|mercedes_benz|               No|     49565|     12|\n",
      "|10400.0|control|        coupe|   Manual|    160|scirocco|   100000|                  4|  Petrol|   volkswagen|               No|     75365|      7|\n",
      "+-------+-------+-------------+---------+-------+--------+---------+-------------------+--------+-------------+-----------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"OutlierRemoval\").getOrCreate()\n",
    "\n",
    "def calculate_quantiles(spark_df):\n",
    "    quantiles = {}\n",
    "    for column in spark_df.columns:\n",
    "        if spark_df.schema[column].dataType in ('double', 'float'):\n",
    "            result = spark_df.selectExpr(f\"percentile_approx({column}, array(0.1, 0.9)) as quantiles\").first()\n",
    "            if result and result['quantiles']:\n",
    "                # Check if the quantiles list has exactly 2 elements\n",
    "                if len(result['quantiles']) == 2:\n",
    "                    quantiles[column] = {\n",
    "                        'Q1': result['quantiles'][0],\n",
    "                        'Q3': result['quantiles'][1]\n",
    "                    }\n",
    "                else:\n",
    "                    print(f\"Unexpected quantiles length for column: {column}\")\n",
    "                    quantiles[column] = {'Q1': None, 'Q3': None}\n",
    "            else:\n",
    "                print(f\"Quantile calculation failed for column: {column}\")\n",
    "                quantiles[column] = {'Q1': None, 'Q3': None}\n",
    "    return quantiles\n",
    "\n",
    "def remove_outliers(spark_df):\n",
    "    quantile_dict = calculate_quantiles(spark_df)\n",
    "    \n",
    "    filters = []\n",
    "    for column, stats in quantile_dict.items():\n",
    "        if stats['Q1'] is not None and stats['Q3'] is not None:\n",
    "            Q1 = stats['Q1']\n",
    "            Q3 = stats['Q3']\n",
    "            IQR = Q3 - Q1\n",
    "            filters.append(\n",
    "                (col(column) >= (Q1 - 1.5 * IQR)) & (col(column) <= (Q3 + 1.5 * IQR))\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Skipping column {column} due to missing quantiles.\")\n",
    "    \n",
    "    if filters:\n",
    "        combined_filter = filters[0]\n",
    "        for f in filters[1:]:\n",
    "            combined_filter = combined_filter & f\n",
    "\n",
    "        filtered_df = spark_df.filter(combined_filter)\n",
    "    else:\n",
    "        print(\"No valid filters were applied.\")\n",
    "        filtered_df = spark_df\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Assuming `df_dropped` is your DataFrame\n",
    "clean_user_car = remove_outliers(df_dropped)\n",
    "\n",
    "# Show the cleaned DataFrame\n",
    "clean_user_car.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4e7d57a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading  the data to the Hive wearhouse\n",
    "df2=clean_user_car\n",
    "tablename=\"Project_Autos.autos_Data_Modified\"\n",
    "df2.write.mode(\"overwrite\").saveAsTable(tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b16bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"DataFor_Analysis\"  # Change this to your desired output path\n",
    "#df_VehicleCopy=df\n",
    "#pandas_df = df_VehicleCopy.toPandas()\n",
    "# Save DataFrame to CSV\n",
    "df2.write.csv(output_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "38f2d6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading https://files.pythonhosted.org/packages/58/d9/796181a30827b12101786c21301f0f4536597a9249530916b1fdb5bbad91/openpyxl-3.1.3-py2.py3-none-any.whl (251kB)\n",
      "\u001b[K    100% |████████████████████████████████| 256kB 391kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting et-xmlfile (from openpyxl)\n",
      "  Downloading https://files.pythonhosted.org/packages/96/c2/3dd434b0108730014f1b96fd286040dc3bcb70066346f7e01ec2ac95865f/et_xmlfile-1.1.0-py3-none-any.whl\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "044f37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6e9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
